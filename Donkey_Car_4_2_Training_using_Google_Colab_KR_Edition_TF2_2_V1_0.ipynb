{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Donkey Car-4.2_Training using Google Colab-KR Edition-TF2.2-V1.0",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pletalk/EMPV-RPI-Donkeycar-4.1/blob/main/Donkey_Car_4_2_Training_using_Google_Colab_KR_Edition_TF2_2_V1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlmQIFSLZDdc"
      },
      "source": [
        "# 동키카 4.2 지원 Google Colaboratory를 활용한 동키카 학습을 위한 단계별 가이드\n",
        "\n",
        "@2021-06-29/Ignitespark\n",
        "\n",
        "Google에서 지원하는 Colaboratory 환경에서 Donkey의 주행 영상데이타를 활용해서 신경회로망의 학습을 단계적으로 수행하도록 안내하는 노트북입니다. 4.2에서는 Tensorflow 2.0이상을 지원합니다.\n",
        "\n",
        "원할한 수행을 위해서 메뉴의 런타임 > 런타임 유형변경에서 GPU/TPU를 선택해 주세요.\n",
        "\n",
        "<참고>\n",
        "* donkeycar visualization - https://colab.research.google.com/github/uwesterr/MlFastAiBlog/blob/master/_notebooks/2020-03-01-TrainDonkeyCar.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcxPuVeq6rQI"
      },
      "source": [
        "# 0 > Google Colaboratory를 사용하기 전에 알아두어야할 사항들"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z17oTx4n6xn_"
      },
      "source": [
        "Google Colaboratory는 구글이 지원하는 머신러닝 및 데이타처리를 위한 무료 서비스 플랫폼입니다. Google Colaboratory에서는 고성능의 GPU를 제공하여 머신러닝의 학습속도를 빠르게 수행할 수 있는 우수한 기능을 제공하고 있습니다. 이런 기능들을 활용하는데 있어서 반드시 알아두어야할 사항들은 아래와 같습니다.\n",
        "\n",
        "\n",
        "* Google Colaboratory는 12시간 동안만 사용 가능합니다. 사용자가 프로그램 수행을 위한 노트를 개설하고 수행하는데 있어서 최대 12시간 이내에서만 사용할 수 있습니다. Google Colaboratory는 12시간이 지나면 개인에게 할당했던 모든 컴퓨팅 자원(CPU,메모리,GPU등)을 리셋(재설정)합니다.\n",
        "\n",
        "* 12시간 이내라도 80분간 사용하지 않으면, 개인에게 할당했던 모든 컴퓨팅 자원(CPU,메모리,GPU등)을 리셋(재설정)합니다.\n",
        "\n",
        "* 할당된 자원이 리셋(재설정)되었다고 다시 사용하지 못하는 것은 아닙니다. 개인의 구글 드라이브에 저장된 Google Laboratory에서 작성한 주피터 노트북을 다시 로드하고 프로젝트를 새로이 시작하면 됩니다. 또 다른 12시간의 개발과 테스팅 시간이 시작됩니다.\n",
        "\n",
        "* Google Laboratory에서 수행한 내용들은 주피터 노트북에 과정과 내용을 기록하여 재 사용가능하도록 합니다. 생성하거나 사용한 노트북은 개인의 구글 드라이브에 파일로 저장이 가능합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l4MpFXFip98"
      },
      "source": [
        "# 1 > Google Colaboratory의 컴퓨팅 환경\n",
        "\n",
        "구글의 Colaboratory에서 지원되는 기본적인 컴퓨팅 환경의 다양한 정보들을 통해 성능을 확인해봅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJjLud26jNI7"
      },
      "source": [
        "## 1.1 OS 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og0R-h2zipTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602eb34e-bac5-4d70-d30e-46a6b63f024d"
      },
      "source": [
        "! cat /etc/issue.net"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ubuntu 18.04.5 LTS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4QMph5LjUeE"
      },
      "source": [
        "## 1.2 Google Colaboratory GPU 정보보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8tmMHYcjZ4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dbdb822-be81-4792-ef6b-e2f434ebc661"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun 29 11:45:27 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU6Q-ZqFjp1M"
      },
      "source": [
        "## 1.3 메모리 용량 파악하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC0zt4zNjqK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2882f0f-5708-4bef-bb34-28924b98755e"
      },
      "source": [
        "! cat /proc/meminfo"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MemTotal:       13305360 kB\n",
            "MemFree:        10526468 kB\n",
            "MemAvailable:   12462248 kB\n",
            "Buffers:           85696 kB\n",
            "Cached:          1994660 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           970444 kB\n",
            "Inactive:        1512700 kB\n",
            "Active(anon):     375532 kB\n",
            "Inactive(anon):      440 kB\n",
            "Active(file):     594912 kB\n",
            "Inactive(file):  1512260 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:              1440 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:        402860 kB\n",
            "Mapped:           240416 kB\n",
            "Shmem:              1168 kB\n",
            "KReclaimable:     140376 kB\n",
            "Slab:             192748 kB\n",
            "SReclaimable:     140376 kB\n",
            "SUnreclaim:        52372 kB\n",
            "KernelStack:        5008 kB\n",
            "PageTables:         5520 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6652680 kB\n",
            "Committed_AS:    3201612 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       47200 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1424 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      144584 kB\n",
            "DirectMap2M:     5097472 kB\n",
            "DirectMap1G:    10485760 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhlZkOuQj1kW"
      },
      "source": [
        "## 1.4 CPU 정보 파악하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e4y0p2fj1sq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfaaffe6-a507-4912-e310-ab94b5c60117"
      },
      "source": [
        "! cat /proc/cpuinfo"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 85\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "stepping\t: 3\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2000.138\n",
            "cache size\t: 39424 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4000.27\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 85\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "stepping\t: 3\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2000.138\n",
            "cache size\t: 39424 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4000.27\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liQZb4cDmZgy"
      },
      "source": [
        "# 2 > 텐서플로우 2.2으로 변경하기\n",
        "텐서플로우(tensorflow)와 Keras의 설치 버전을 확인합니다.\n",
        "* Google Colab에서는 tensorflow의 기본버전으로 2.5.X가 설치\n",
        "* donkeycar의 학습을 위해서 2.2.0버전을 재설치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlwBE9ZyAM62"
      },
      "source": [
        "### 2.1 텐서플로우 버전확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmyx7POJIIKa",
        "outputId": "80dc5db7-4ca8-45b1-bad7-5b4ab99feae4"
      },
      "source": [
        "! pip show tensorflow"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.5.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: h5py, termcolor, flatbuffers, tensorflow-estimator, six, protobuf, keras-nightly, gast, keras-preprocessing, tensorboard, numpy, absl-py, wheel, google-pasta, opt-einsum, grpcio, astunparse, typing-extensions, wrapt\n",
            "Required-by: kapre\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuaMzPDpAQrZ"
      },
      "source": [
        "### 2.2 Tensorflow 2.2.0 버전 설치하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ4Tj0NWISa1",
        "outputId": "f20e16e6-3ca9-45ad-85f9-3b7e71d6414a"
      },
      "source": [
        "! pip install tensorflow==2.2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/1a/0d79814736cfecc825ab8094b39648cc9c46af7af1bae839928acb73b4dd/tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 21kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.12.0)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.36.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (3.12.4)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 95kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.34.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.6.3)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow==2.2) (57.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.31.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.3.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.2.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2021.5.30)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.4.1)\n",
            "Installing collected packages: h5py, tensorboard, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0jlUIVKIeZk",
        "outputId": "70bd9a37-6277-4386-a779-32d272068b8a"
      },
      "source": [
        "! pip show tensorflow"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.2.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: wrapt, grpcio, astunparse, numpy, termcolor, scipy, gast, absl-py, tensorflow-estimator, wheel, opt-einsum, google-pasta, tensorboard, keras-preprocessing, six, protobuf, h5py\n",
            "Required-by: kapre\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yBuDMkIAUcu"
      },
      "source": [
        "### 2.3 설치된 tensorflow 버전 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6Jbr1_x5YHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70affe7e-3a32-460b-9686-0f55a44cf425"
      },
      "source": [
        "#import keras\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arsH-DhLcihq"
      },
      "source": [
        "### 2.4  GPU 확인하기\n",
        "\n",
        "\"Found GPU at: / device: GPU: 0\"이 표시되면, GPU가 이미 사용중이라는 의미입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQgEhuoTcg0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90926463-bbbf-47bd-8379-4f0cb7e07733"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba2oPDIrsDFg"
      },
      "source": [
        "# 3 > Donkeycar 프로그램 설치 (4.x)\n",
        "\n",
        "* 2020-11-11일자 기준 4.x버전을 설치 \n",
        "\n",
        "* Donkeycar의 영상데이타 기반의 학습프로그램을 활용하기 위해서 Donkeycar의 프로그램들을 Google Colaboratory에 설치해야 합니다.\n",
        "\n",
        "* Git에 저장되어 있는 Donkeycar 프로그램 저장소에서 관련 소스코드를 가져와서 Google Colaboratory에 폴더를 생성하고 해당 소스코드를 복사하여 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wa58PkkLCOzp",
        "outputId": "db047ce2-4b1d-47ba-ca40-918cde25c24b"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOxd9PFUyNxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a6cd4f-6994-4496-ef39-66c2ff6695b1"
      },
      "source": [
        "! git clone https://github.com/autorope/donkeycar\n",
        "%cd donkeycar\n",
        "! git checkout master"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'donkeycar'...\n",
            "remote: Enumerating objects: 13676, done.\u001b[K\n",
            "remote: Counting objects: 100% (594/594), done.\u001b[K\n",
            "remote: Compressing objects: 100% (324/324), done.\u001b[K\n",
            "remote: Total 13676 (delta 362), reused 435 (delta 270), pack-reused 13082\u001b[K\n",
            "Receiving objects: 100% (13676/13676), 89.07 MiB | 39.45 MiB/s, done.\n",
            "Resolving deltas: 100% (8886/8886), done.\n",
            "/content/donkeycar\n",
            "Branch 'master' set up to track remote branch 'master' from 'origin'.\n",
            "Switched to a new branch 'master'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E8pOE73l3Fn"
      },
      "source": [
        "### (Q) 저장된 Donkeycar 소스코드는 어디에 ?\n",
        "\n",
        "Git에서 가져온 코드들은 Google Colaboratory의 탐색창의 상단의 파일 메뉴를 클릭하면 설치된 소스코드의 디렉토리를 아래와 같이 확인이 가능합니다.\n",
        "\n",
        "* Google Colaboratory의 파일은 /content 아래에 위치합니다.\n",
        "\n",
        "![DonkeyCar Git Source Codes Folder](https://api.monosnap.com/file/download?id=Apc4BB8AwlJ1tryBBykAzdnxvAwTw1)\n",
        "\n",
        "* 사용자가 /content 디렉토리 아래에 mydata라는 새로운 디렉토리(폴더)를 생성했다면, 실제 Google Colaboratory에서는 /content/mydata 라는 폴더가 생성됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TkkcF-gsAnx"
      },
      "source": [
        "## 3.1 DonkeyCar 프로그램 설치하기\n",
        "\n",
        "DonkeyCar 프로그램 소스코드가 저장된 donkey폴더 내의 setup.py 파일을 사용해서 설치를 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz_PZgrByPDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9066f5-7f6a-46a1-dac2-24a012ef5bea"
      },
      "source": [
        "! pip install -e .[pc]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/donkeycar\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from donkeycar==4.2.1) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from donkeycar==4.2.1) (7.1.2)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from donkeycar==4.2.1) (0.6.2)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from donkeycar==4.2.1) (5.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from donkeycar==4.2.1) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from donkeycar==4.2.1) (2.10.0)\n",
            "Requirement already satisfied: PrettyTable in /usr/local/lib/python3.7/dist-packages (from donkeycar==4.2.1) (2.1.0)\n",
            "Collecting paho-mqtt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/d3/6dcb8fd14746fcde6a556f932b5de8bea8fedcb85b3a092e0e986372c0e7/paho-mqtt-1.5.1.tar.gz (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 5.2MB/s \n",
            "\u001b[?25hCollecting simple_pid\n",
            "  Downloading https://files.pythonhosted.org/packages/39/72/489743f43655a6f168bd9ac1e24a2daf9c44998f19d7bbd8e7f070b3f451/simple_pid-1.0.1-py2.py3-none-any.whl\n",
            "Collecting progress\n",
            "  Downloading https://files.pythonhosted.org/packages/38/ef/2e887b3d2b248916fc2121889ce68af8a16aaddbe82f9ae6533c24ff0d2b/progress-1.5.tar.gz\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from donkeycar==4.2.1) (3.7.4.3)\n",
            "Collecting pyfiglet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/07/fcfdd7a2872f5b348953de35acce1544dab0c1e8368dca54279b1cde5c15/pyfiglet-0.8.post1-py2.py3-none-any.whl (865kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from donkeycar==4.2.1) (5.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from donkeycar==4.2.1) (3.2.2)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from donkeycar==4.2.1) (0.2.9)\n",
            "Collecting kivy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/d9/0d06e8dc8be200e5cca19e4cd011ef3919bdf0bd4a50e5e2018d7c61a371/Kivy-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (19.2MB)\n",
            "\u001b[K     |████████████████████████████████| 19.2MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->donkeycar==4.2.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->donkeycar==4.2.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->donkeycar==4.2.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->donkeycar==4.2.1) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->donkeycar==4.2.1) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from PrettyTable->donkeycar==4.2.1) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from PrettyTable->donkeycar==4.2.1) (4.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->donkeycar==4.2.1) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->donkeycar==4.2.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->donkeycar==4.2.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->donkeycar==4.2.1) (0.10.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug->donkeycar==4.2.1) (2.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug->donkeycar==4.2.1) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug->donkeycar==4.2.1) (0.16.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug->donkeycar==4.2.1) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->donkeycar==4.2.1) (1.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from kivy->donkeycar==4.2.1) (2.6.1)\n",
            "Collecting Kivy-Garden>=0.1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/68/decaee596ff8168a39432eb3949fc7c0be952ebb9467806823bffc165d48/kivy-garden-0.1.4.tar.gz\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.7/dist-packages (from kivy->donkeycar==4.2.1) (0.17.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->PrettyTable->donkeycar==4.2.1) (3.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug->donkeycar==4.2.1) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug->donkeycar==4.2.1) (2.5.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug->donkeycar==4.2.1) (4.4.2)\n",
            "Building wheels for collected packages: paho-mqtt, progress, Kivy-Garden\n",
            "  Building wheel for paho-mqtt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paho-mqtt: filename=paho_mqtt-1.5.1-cp37-none-any.whl size=61565 sha256=f1844ded55234a1fe7867cada5667891568cf816d58da158231a1a0adad7dec7\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/e2/f5/78942b19b4d135605e58dfe85fba52253b14d636aabf76904b\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.5-cp37-none-any.whl size=8088 sha256=7a13c447d6f7388474a5ab8191ae87e65dbcaed84c9d9844667a587852b959c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/c8/80/32a294e3041f006c661838c05a411c7b7ffc60ff939d14e116\n",
            "  Building wheel for Kivy-Garden (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Kivy-Garden: filename=Kivy_Garden-0.1.4-cp37-none-any.whl size=4533 sha256=34593efa0f9daa4e9878b7f235f85820220ebbaeeb58c9dc16046ae79c818922\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/09/36/4bec048252175b6aa7ba75441cbeed8f31a0bea37abedcfed0\n",
            "Successfully built paho-mqtt progress Kivy-Garden\n",
            "Installing collected packages: paho-mqtt, simple-pid, progress, pyfiglet, Kivy-Garden, kivy, donkeycar\n",
            "  Running setup.py develop for donkeycar\n",
            "Successfully installed Kivy-Garden-0.1.4 donkeycar kivy-2.0.0 paho-mqtt-1.5.1 progress-1.5 pyfiglet-0.8.post1 simple-pid-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTJTkh542XM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47011aeb-3bba-46ab-cbaf-7d35a0afa63e"
      },
      "source": [
        "!pip list | grep tensorflow"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow                    2.2.0               \n",
            "tensorflow-datasets           4.0.1               \n",
            "tensorflow-estimator          2.2.0               \n",
            "tensorflow-gcs-config         2.5.0               \n",
            "tensorflow-hub                0.12.0              \n",
            "tensorflow-metadata           1.0.0               \n",
            "tensorflow-probability        0.12.1              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syCctLq2r4Wk"
      },
      "source": [
        "## 3.2 DonkeyCar 프로젝트 생성하기\n",
        "\n",
        "DonkeyCar에 대한 나만의 프로젝트를 새로이 생성합니다. 프로젝트를 생성하기 위해서는 프로젝트 이름이 필요합니다. 여기서는 mycar라는 프로젝트명을 사용합니다. Donkeycar의 프로젝트 생성 형식은 다음과 같습니다.\n",
        "\n",
        "$ donkey createcar --path /content/mycar [enter]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xjJBSITyXy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981c1820-21f4-43f7-a842-bc9247e9c29f"
      },
      "source": [
        "! donkey createcar --path /content/mycar"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "________             ______                   _________              \n",
            "___  __ \\_______________  /___________  __    __  ____/_____ ________\n",
            "__  / / /  __ \\_  __ \\_  //_/  _ \\_  / / /    _  /    _  __ `/_  ___/\n",
            "_  /_/ // /_/ /  / / /  ,<  /  __/  /_/ /     / /___  / /_/ /_  /    \n",
            "/_____/ \\____//_/ /_//_/|_| \\___/_\\__, /      \\____/  \\__,_/ /_/     \n",
            "                                 /____/                              \n",
            "\n",
            "using donkey v4.2.1 ...\n",
            "Creating car folder: /content/mycar\n",
            "making dir  /content/mycar\n",
            "Creating data & model folders.\n",
            "making dir  /content/mycar/models\n",
            "making dir  /content/mycar/data\n",
            "making dir  /content/mycar/logs\n",
            "Copying car application template: complete\n",
            "Copying car config defaults. Adjust these before starting your car.\n",
            "Copying train script. Adjust these before starting your car.\n",
            "Copying calibrate script. Adjust these before starting your car.\n",
            "Copying my car config overrides\n",
            "Donkey setup complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkEtUoKIq2Ua"
      },
      "source": [
        "### (Q) 생성된 mycar 프로젝트는 어디에 ?\n",
        "\n",
        "탐색창의 파일을 클릭하면, 다음과 같이 /content 디렉토리 아래에 mycar폴더가 새롭게 생성되었다는 것을 확인할 수 있습니다. mycar폴더에는 3개의 폴더와 4개의 파이썬 파일이 생성됩니다.\n",
        "\n",
        "![Donkeycar User-Defined Project Folder](https://api.monosnap.com/file/download?id=yMcfRjpwpEpeZIkCqiq2nfX7ihdFjX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh8U5wbO_tov"
      },
      "source": [
        "# 4> 데이타 업로드하기(주행 학습데이타)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnUy1Z1zro77"
      },
      "source": [
        "## 4.1 라즈베리파이의 주행데이타를 Google Colaboratory로 이동 준비(PC/노트북)\n",
        "\n",
        "* 라즈베리파이에 저장된 주행 영상데이타는 프로젝트 파일 폴더(예를 들어 mycar라고 가정) 아래에 data 폴더 아래에 tub_라는 이름을 시작하는 폴더에 순차번호를 붙여서 저장되어 있습니다. 예를들어, 폴더명이 tub_1_19-11-09라면, 11월 09일에 주행한 첫번째 주행영상이라는 의미로 해석이 가능합니다(~/mycar/data/tub_1_19-11-09).\n",
        "\n",
        "* 주행데이타는 개별(1회분의 주행영상)은 물론이고 여러개의 풀더(여러번의 주행영상들)을 모두 학습에 활용할 수 있기때문에 우선 PC로 모두 이동하여 저장하는 방법이 유용합니다.\n",
        "\n",
        "* 라즈베리파이 SD카드로부터 폴더 단위의 복사를 완료했다면, tub_ 폴더들을 Google Laboratory로 업로드하기 위해서 zip으로 묶고, 압축된 파일을 Google Laboratory로 업로드합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixjmMBKvzrV4"
      },
      "source": [
        "### 4.2 data.zip을 노트북/PC에서 Google Colaboratory로 업로드하기\n",
        "\n",
        "* Donkeycar 4.2에서는 datastore_V2형식으로 데이타가 저장\n",
        "* tub별로 images 디렉토리가 생성되며, catalog_0.catalog라는 메타파일이 생성(주행데이타 저장)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgYaifM5C0dR"
      },
      "source": [
        "## 4.3 data.zip 파일을 mycar로 이동하기\n",
        "\n",
        "* /content 디렉토리에 업로드한 주행데이타인 data.zip을 mycar로 이동"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5urZA74C7fS",
        "outputId": "202cee18-f803-4657-c969-700433ad2b03"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuB2qI0XD6XJ"
      },
      "source": [
        "%mv data.zip ./mycar"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQwFoRLhEPHB",
        "outputId": "1bf5d630-ca36-49df-9661-89660b2df98f"
      },
      "source": [
        "%cd mycar"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mycar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl66HeVTEReD",
        "outputId": "226f5166-87ef-4653-8c74-0909092aa0d6"
      },
      "source": [
        "%ls -l"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 26540\n",
            "-rwx------ 1 root root     3371 Jun 29 11:52 \u001b[0m\u001b[01;32mcalibrate.py\u001b[0m*\n",
            "-rw-r--r-- 1 root root    18506 Jun 29 11:52 config.py\n",
            "drwxr-xr-x 2 root root     4096 Jun 29 11:52 \u001b[01;34mdata\u001b[0m/\n",
            "-rw-r--r-- 1 root root 27077786 Jun 29 11:48 data.zip\n",
            "drwxr-xr-x 2 root root     4096 Jun 29 11:52 \u001b[01;34mlogs\u001b[0m/\n",
            "-rwx------ 1 root root    30707 Jun 29 11:52 \u001b[01;32mmanage.py\u001b[0m*\n",
            "drwxr-xr-x 2 root root     4096 Jun 29 11:52 \u001b[01;34mmodels\u001b[0m/\n",
            "-rw-r--r-- 1 root root    19183 Jun 29 11:52 myconfig.py\n",
            "-rwx------ 1 root root      728 Jun 29 11:52 \u001b[01;32mtrain.py\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN07Zl1_Ed_d"
      },
      "source": [
        "### 4.4 data.zip 파일 압축풀기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W-IO2ypEkYD",
        "outputId": "3c605550-acc8-4c5e-ca12-ea6722885b5b"
      },
      "source": [
        "! unzip"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UnZip 6.00 of 20 April 2009, by Debian. Original by Info-ZIP.\n",
            "\n",
            "Usage: unzip [-Z] [-opts[modifiers]] file[.zip] [list] [-x xlist] [-d exdir]\n",
            "  Default action is to extract files in list, except those in xlist, to exdir;\n",
            "  file[.zip] may be a wildcard.  -Z => ZipInfo mode (\"unzip -Z\" for usage).\n",
            "\n",
            "  -p  extract files to pipe, no messages     -l  list files (short format)\n",
            "  -f  freshen existing files, create none    -t  test compressed archive data\n",
            "  -u  update files, create if necessary      -z  display archive comment only\n",
            "  -v  list verbosely/show version info       -T  timestamp archive to latest\n",
            "  -x  exclude files that follow (in xlist)   -d  extract files into exdir\n",
            "modifiers:\n",
            "  -n  never overwrite existing files         -q  quiet mode (-qq => quieter)\n",
            "  -o  overwrite files WITHOUT prompting      -a  auto-convert any text files\n",
            "  -j  junk paths (do not make directories)   -aa treat ALL files as text\n",
            "  -U  use escapes for all non-ASCII Unicode  -UU ignore any Unicode fields\n",
            "  -C  match filenames case-insensitively     -L  make (some) names lowercase\n",
            "  -X  restore UID/GID info                   -V  retain VMS version numbers\n",
            "  -K  keep setuid/setgid/tacky permissions   -M  pipe through \"more\" pager\n",
            "  -O CHARSET  specify a character encoding for DOS, Windows and OS/2 archives\n",
            "  -I CHARSET  specify a character encoding for UNIX and other archives\n",
            "\n",
            "See \"unzip -hh\" or unzip.txt for more help.  Examples:\n",
            "  unzip data1 -x joe   => extract all files except joe from zipfile data1.zip\n",
            "  unzip -p foo | more  => send contents of foo.zip via pipe into program more\n",
            "  unzip -fo foo ReadMe => quietly replace existing ReadMe if archive file newer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_BgZDgeEpOY",
        "outputId": "5c203fd4-362c-4789-f59f-f749b8773061"
      },
      "source": [
        "# 압축을 풀기전에 data.zip에 어떤 파일들이 들어있는지 확인하기\n",
        "# 앞에서 몇줄만 확인\n",
        "\n",
        "! unzip -v data.zip | head "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            " Length   Method    Size  Cmpr    Date    Time   CRC-32   Name\n",
            "--------  ------  ------- ---- ---------- ----- --------  ----\n",
            "       0  Stored        0   0% 2021-06-29 20:27 00000000  data/\n",
            "       0  Stored        0   0% 2021-06-29 20:27 00000000  data/tub_1_21-06-29/\n",
            "  202246  Defl:X     9004  96% 2021-06-29 17:18 bb74b0e4  data/tub_1_21-06-29/catalog_0.catalog\n",
            "    5109  Defl:X      376  93% 2021-06-29 17:18 24fe1288  data/tub_1_21-06-29/catalog_0.catalog_manifest\n",
            "   78015  Defl:X     3706  95% 2021-06-29 17:18 4787864d  data/tub_1_21-06-29/catalog_1.catalog\n",
            "    2022  Defl:X      198  90% 2021-06-29 17:18 7e9a7174  data/tub_1_21-06-29/catalog_1.catalog_manifest\n",
            "       0  Stored        0   0% 2021-06-29 20:27 00000000  data/tub_1_21-06-29/images/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q3FzTYbie6cl",
        "outputId": "1b2bb16a-86d7-40b3-8852-de37c4563318"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/mycar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3XBPK0aFXaW"
      },
      "source": [
        "# 기존의 data 디렉토리 삭제하기\n",
        "\n",
        "%rm -r data"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uSR3SPBFB6v"
      },
      "source": [
        "# 압축풀기\n",
        "\n",
        "! unzip -qox data.zip"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZfLowRSfQce",
        "outputId": "6471a503-77d8-4ce1-a1a5-a5219734b1d2"
      },
      "source": [
        "%ls -l"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 26540\n",
            "-rwx------ 1 root root     3371 Jun 29 11:52 \u001b[0m\u001b[01;32mcalibrate.py\u001b[0m*\n",
            "-rw-r--r-- 1 root root    18506 Jun 29 11:52 config.py\n",
            "drwxr-xr-x 7 root root     4096 Jun 29  2021 \u001b[01;34mdata\u001b[0m/\n",
            "-rw-r--r-- 1 root root 27077786 Jun 29 11:48 data.zip\n",
            "drwxr-xr-x 2 root root     4096 Jun 29 11:52 \u001b[01;34mlogs\u001b[0m/\n",
            "-rwx------ 1 root root    30707 Jun 29 11:52 \u001b[01;32mmanage.py\u001b[0m*\n",
            "drwxr-xr-x 2 root root     4096 Jun 29 11:52 \u001b[01;34mmodels\u001b[0m/\n",
            "-rw-r--r-- 1 root root    19183 Jun 29 11:52 myconfig.py\n",
            "-rwx------ 1 root root      728 Jun 29 11:52 \u001b[01;32mtrain.py\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc5qH-pIGJ2s"
      },
      "source": [
        "### 4.5 data 디렉토리에 주행데이타 압축해제 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9OARUfjhfpk3",
        "outputId": "c2d15465-afb9-4efd-ab15-1f5ecd601697"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/mycar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79ITZV7LGQwa",
        "outputId": "55241497-9ec1-4efc-f9ca-245d5c2e4eeb"
      },
      "source": [
        "%ls -l data"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 3 root root 4096 Jun 29  2021 \u001b[0m\u001b[01;34mtub_1_21-06-29\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4096 Jun 29  2021 \u001b[01;34mtub_2_21-06-29\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4096 Jun 29  2021 \u001b[01;34mtub_3_21-06-29\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4096 Jun 29  2021 \u001b[01;34mtub_4_21-06-29\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4096 Jun 29  2021 \u001b[01;34mtub_5_21-06-29\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-3U5MnYoZPY"
      },
      "source": [
        "### 4.6  업로드된 data.zip 파일 삭제하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oifxa-VXGcV7"
      },
      "source": [
        "%rm -r data.zip"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3Ya8qEUAfOv"
      },
      "source": [
        "# 5> Donkeycar 주행영상데이타를 활용한 자율주행모델 학습하기\n",
        "\n",
        "동키카에서 지원되는 학습모듈을 사용해서 주행영상 데이타 기반의 인공지능 학습을 진행합니다. CNN(Convolution Neural Network)기반의 이미지 식별을 통한 모델 학습으로 주행영상과 실제 주행시 함께 획득한 속도와 주행방향에 대한 데이타를 입력으로 하여 주행 모델을 학습하게 됩니다.\n",
        "\n",
        "* tub_ 디렉토리가 적은 경우, 학습이 되지 않습니다. 최소 10개이상의 주행을 하고 학습하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqgaPmDU0tH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8852f6b1-5abc-47a0-e270-76e41060c3be"
      },
      "source": [
        "!python /content/mycar/train.py"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "________             ______                   _________              \n",
            "___  __ \\_______________  /___________  __    __  ____/_____ ________\n",
            "__  / / /  __ \\_  __ \\_  //_/  _ \\_  / / /    _  /    _  __ `/_  ___/\n",
            "_  /_/ // /_/ /  / / /  ,<  /  __/  /_/ /     / /___  / /_/ /_  /    \n",
            "/_____/ \\____//_/ /_//_/|_| \\___/_\\__, /      \\____/  \\__,_/ /_/     \n",
            "                                 /____/                              \n",
            "\n",
            "using donkey v4.2.1 ...\n",
            "Usage:\n",
            "    train.py [--tubs=tubs] (--model=<model>)\n",
            "    [--type=(linear|inferred|tensorrt_linear|tflite_linear)]\n",
            "    [--comment=<comment>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8CXjWDrNai_"
      },
      "source": [
        "## 5.1 tubs 파일경로 설정하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR63qxesNjbL",
        "outputId": "6f4644bc-df2b-4782-cba2-603e1cfe5534"
      },
      "source": [
        "import os\n",
        "\n",
        "dir_list = os.listdir('/content/mycar/data')\n",
        "print(dir_list)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tub_1_21-06-29', 'tub_2_21-06-29', 'tub_4_21-06-29', 'tub_3_21-06-29', 'tub_5_21-06-29']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ufILwVHf7Vq"
      },
      "source": [
        "dir_list2 = []\n",
        "for x in dir_list:\n",
        "    if x.find(\"tub_\") > -1:\n",
        "        dir_list2.append(x)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srI1qVj7Gz57",
        "outputId": "03e67ac8-6d37-4b2f-cd79-d44cc29b294c"
      },
      "source": [
        "sorted(dir_list2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tub_1_21-06-29',\n",
              " 'tub_2_21-06-29',\n",
              " 'tub_3_21-06-29',\n",
              " 'tub_4_21-06-29',\n",
              " 'tub_5_21-06-29']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ng_byPBfOEbi",
        "outputId": "51b3d408-c9d7-43a3-f8fe-67a243cf5979"
      },
      "source": [
        "DATA_DIR = 'data'\n",
        "tubs_list = ','.join([ \"%s/%s\" % (DATA_DIR,x) for x in sorted(dir_list2)])\n",
        "tubs_list"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data/tub_1_21-06-29,data/tub_2_21-06-29,data/tub_3_21-06-29,data/tub_4_21-06-29,data/tub_5_21-06-29'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmRtjhxVKvQQ"
      },
      "source": [
        "[주의] \n",
        "\n",
        "*   학습데이타가 128개보다 작은 경우, 오류가 발생(validation_step에서 오류발생)\n",
        "*   위의 경우, config.py파일의 BATCH_SIZE를 총 데이타갯수보다 작게 설정(e.g) BATCH_SIZE=64\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdiyt3fZQeuX"
      },
      "source": [
        "## 5.2 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCvUUnaHzwx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb97f0d-9ec7-4568-c82f-20f0c70f96ba"
      },
      "source": [
        "#\n",
        "# 학습을 위한 데이타는 /data 디렉토리 아래의 tub_ 이름의 폴더에서 자동으로 가져와서 학습을 수행\n",
        "#\n",
        "! python /content/mycar/train.py --tubs {tubs_list} --model /content/mycar/models/mypilot.h5"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "________             ______                   _________              \n",
            "___  __ \\_______________  /___________  __    __  ____/_____ ________\n",
            "__  / / /  __ \\_  __ \\_  //_/  _ \\_  / / /    _  /    _  __ `/_  ___/\n",
            "_  /_/ // /_/ /  / / /  ,<  /  __/  /_/ /     / /___  / /_/ /_  /    \n",
            "/_____/ \\____//_/ /_//_/|_| \\___/_\\__, /      \\____/  \\__,_/ /_/     \n",
            "                                 /____/                              \n",
            "\n",
            "using donkey v4.2.1 ...\n",
            "loading config file: /content/mycar/config.py\n",
            "loading personal config over-rides from myconfig.py\n",
            "\"get_model_by_type\" model Type is: linear\n",
            "Created KerasLinear\n",
            "2021-06-29 11:57:16.390797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-29 11:57:16.396372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-29 11:57:16.396937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-06-29 11:57:16.397193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-29 11:57:16.398874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-29 11:57:16.400387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-29 11:57:16.400729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-29 11:57:16.402341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-29 11:57:16.403052: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-29 11:57:16.406378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-29 11:57:16.406504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-29 11:57:16.407135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-29 11:57:16.407680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2021-06-29 11:57:16.407907: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2021-06-29 11:57:16.412726: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2000134999 Hz\n",
            "2021-06-29 11:57:16.412969: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ab6286d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-06-29 11:57:16.412998: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-06-29 11:57:16.494486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-29 11:57:16.495210: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ab6286bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-06-29 11:57:16.495244: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-06-29 11:57:16.495428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-29 11:57:16.496010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-06-29 11:57:16.496080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-29 11:57:16.496108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-29 11:57:16.496132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-29 11:57:16.496154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-29 11:57:16.496174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-29 11:57:16.496194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-29 11:57:16.496214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-29 11:57:16.496287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-29 11:57:16.496862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-29 11:57:16.497354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2021-06-29 11:57:16.497433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-29 11:57:16.498686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-29 11:57:16.498721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2021-06-29 11:57:16.498740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2021-06-29 11:57:16.498858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-29 11:57:16.499406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-29 11:57:16.499935: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-06-29 11:57:16.499976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14012 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img_in (InputLayer)             [(None, 120, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 58, 78, 24)   1824        img_in[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 58, 78, 24)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 27, 37, 32)   19232       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 27, 37, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 12, 17, 64)   51264       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 12, 17, 64)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 10, 15, 64)   36928       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 10, 15, 64)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 13, 64)    36928       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 8, 13, 64)    0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flattened (Flatten)             (None, 6656)         0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          665700      flattened[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 50)           5050        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 50)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "n_outputs0 (Dense)              (None, 1)            51          dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "n_outputs1 (Dense)              (None, 1)            51          dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 817,028\n",
            "Trainable params: 817,028\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Using catalog /content/mycar/data/tub_1_21-06-29/catalog_1.catalog\n",
            "Using catalog /content/mycar/data/tub_2_21-06-29/catalog_1.catalog\n",
            "Using catalog /content/mycar/data/tub_3_21-06-29/catalog_1.catalog\n",
            "Using catalog /content/mycar/data/tub_4_21-06-29/catalog_1.catalog\n",
            "Using catalog /content/mycar/data/tub_5_21-06-29/catalog_1.catalog\n",
            "\n",
            "Records # Training 5092\n",
            "Records # Validation 1273\n",
            "Epoch 1/100\n",
            "2021-06-29 11:57:17.920657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-29 11:57:19.338538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0793 - n_outputs0_loss: 0.0675 - n_outputs1_loss: 0.0118\n",
            "Epoch 00001: val_loss improved from inf to 0.04781, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 9s 232ms/step - loss: 0.0793 - n_outputs0_loss: 0.0675 - n_outputs1_loss: 0.0118 - val_loss: 0.0478 - val_n_outputs0_loss: 0.0465 - val_n_outputs1_loss: 0.0013\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0469 - n_outputs0_loss: 0.0434 - n_outputs1_loss: 0.0035\n",
            "Epoch 00002: val_loss improved from 0.04781 to 0.03732, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.0469 - n_outputs0_loss: 0.0434 - n_outputs1_loss: 0.0035 - val_loss: 0.0373 - val_n_outputs0_loss: 0.0346 - val_n_outputs1_loss: 0.0028\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0316 - n_outputs0_loss: 0.0281 - n_outputs1_loss: 0.0036\n",
            "Epoch 00003: val_loss improved from 0.03732 to 0.02846, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 155ms/step - loss: 0.0316 - n_outputs0_loss: 0.0281 - n_outputs1_loss: 0.0036 - val_loss: 0.0285 - val_n_outputs0_loss: 0.0268 - val_n_outputs1_loss: 0.0017\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0256 - n_outputs0_loss: 0.0229 - n_outputs1_loss: 0.0027\n",
            "Epoch 00004: val_loss improved from 0.02846 to 0.02068, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.0256 - n_outputs0_loss: 0.0229 - n_outputs1_loss: 0.0027 - val_loss: 0.0207 - val_n_outputs0_loss: 0.0193 - val_n_outputs1_loss: 0.0014\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0226 - n_outputs0_loss: 0.0204 - n_outputs1_loss: 0.0023\n",
            "Epoch 00005: val_loss improved from 0.02068 to 0.01848, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 144ms/step - loss: 0.0226 - n_outputs0_loss: 0.0204 - n_outputs1_loss: 0.0023 - val_loss: 0.0185 - val_n_outputs0_loss: 0.0176 - val_n_outputs1_loss: 8.7803e-04\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0206 - n_outputs0_loss: 0.0186 - n_outputs1_loss: 0.0020\n",
            "Epoch 00006: val_loss improved from 0.01848 to 0.01816, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 145ms/step - loss: 0.0206 - n_outputs0_loss: 0.0186 - n_outputs1_loss: 0.0020 - val_loss: 0.0182 - val_n_outputs0_loss: 0.0173 - val_n_outputs1_loss: 8.9529e-04\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0197 - n_outputs0_loss: 0.0178 - n_outputs1_loss: 0.0018\n",
            "Epoch 00007: val_loss improved from 0.01816 to 0.01790, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 142ms/step - loss: 0.0197 - n_outputs0_loss: 0.0178 - n_outputs1_loss: 0.0018 - val_loss: 0.0179 - val_n_outputs0_loss: 0.0170 - val_n_outputs1_loss: 9.0929e-04\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0186 - n_outputs0_loss: 0.0170 - n_outputs1_loss: 0.0016\n",
            "Epoch 00008: val_loss improved from 0.01790 to 0.01746, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 144ms/step - loss: 0.0186 - n_outputs0_loss: 0.0170 - n_outputs1_loss: 0.0016 - val_loss: 0.0175 - val_n_outputs0_loss: 0.0167 - val_n_outputs1_loss: 7.6187e-04\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0183 - n_outputs0_loss: 0.0167 - n_outputs1_loss: 0.0016\n",
            "Epoch 00009: val_loss improved from 0.01746 to 0.01508, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.0183 - n_outputs0_loss: 0.0167 - n_outputs1_loss: 0.0016 - val_loss: 0.0151 - val_n_outputs0_loss: 0.0144 - val_n_outputs1_loss: 7.1152e-04\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0165 - n_outputs0_loss: 0.0150 - n_outputs1_loss: 0.0014\n",
            "Epoch 00010: val_loss did not improve from 0.01508\n",
            "40/40 [==============================] - 6s 139ms/step - loss: 0.0165 - n_outputs0_loss: 0.0150 - n_outputs1_loss: 0.0014 - val_loss: 0.0168 - val_n_outputs0_loss: 0.0161 - val_n_outputs1_loss: 7.5270e-04\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0164 - n_outputs0_loss: 0.0150 - n_outputs1_loss: 0.0014\n",
            "Epoch 00011: val_loss did not improve from 0.01508\n",
            "40/40 [==============================] - 6s 144ms/step - loss: 0.0164 - n_outputs0_loss: 0.0150 - n_outputs1_loss: 0.0014 - val_loss: 0.0187 - val_n_outputs0_loss: 0.0179 - val_n_outputs1_loss: 7.6141e-04\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0161 - n_outputs0_loss: 0.0147 - n_outputs1_loss: 0.0013\n",
            "Epoch 00012: val_loss did not improve from 0.01508\n",
            "40/40 [==============================] - 6s 142ms/step - loss: 0.0161 - n_outputs0_loss: 0.0147 - n_outputs1_loss: 0.0013 - val_loss: 0.0152 - val_n_outputs0_loss: 0.0145 - val_n_outputs1_loss: 7.0470e-04\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0152 - n_outputs0_loss: 0.0139 - n_outputs1_loss: 0.0013\n",
            "Epoch 00013: val_loss improved from 0.01508 to 0.01399, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 144ms/step - loss: 0.0152 - n_outputs0_loss: 0.0139 - n_outputs1_loss: 0.0013 - val_loss: 0.0140 - val_n_outputs0_loss: 0.0133 - val_n_outputs1_loss: 6.9811e-04\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0146 - n_outputs0_loss: 0.0133 - n_outputs1_loss: 0.0013\n",
            "Epoch 00014: val_loss did not improve from 0.01399\n",
            "40/40 [==============================] - 6s 141ms/step - loss: 0.0146 - n_outputs0_loss: 0.0133 - n_outputs1_loss: 0.0013 - val_loss: 0.0157 - val_n_outputs0_loss: 0.0150 - val_n_outputs1_loss: 7.2309e-04\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0144 - n_outputs0_loss: 0.0131 - n_outputs1_loss: 0.0012\n",
            "Epoch 00015: val_loss improved from 0.01399 to 0.01272, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 145ms/step - loss: 0.0144 - n_outputs0_loss: 0.0131 - n_outputs1_loss: 0.0012 - val_loss: 0.0127 - val_n_outputs0_loss: 0.0120 - val_n_outputs1_loss: 6.7545e-04\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0138 - n_outputs0_loss: 0.0126 - n_outputs1_loss: 0.0012\n",
            "Epoch 00016: val_loss improved from 0.01272 to 0.01193, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 145ms/step - loss: 0.0138 - n_outputs0_loss: 0.0126 - n_outputs1_loss: 0.0012 - val_loss: 0.0119 - val_n_outputs0_loss: 0.0113 - val_n_outputs1_loss: 6.6269e-04\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0133 - n_outputs0_loss: 0.0121 - n_outputs1_loss: 0.0012\n",
            "Epoch 00017: val_loss did not improve from 0.01193\n",
            "40/40 [==============================] - 6s 141ms/step - loss: 0.0133 - n_outputs0_loss: 0.0121 - n_outputs1_loss: 0.0012 - val_loss: 0.0138 - val_n_outputs0_loss: 0.0131 - val_n_outputs1_loss: 6.9965e-04\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0133 - n_outputs0_loss: 0.0122 - n_outputs1_loss: 0.0011\n",
            "Epoch 00018: val_loss did not improve from 0.01193\n",
            "40/40 [==============================] - 6s 139ms/step - loss: 0.0133 - n_outputs0_loss: 0.0122 - n_outputs1_loss: 0.0011 - val_loss: 0.0129 - val_n_outputs0_loss: 0.0122 - val_n_outputs1_loss: 6.8068e-04\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0132 - n_outputs0_loss: 0.0121 - n_outputs1_loss: 0.0011\n",
            "Epoch 00019: val_loss did not improve from 0.01193\n",
            "40/40 [==============================] - 6s 143ms/step - loss: 0.0132 - n_outputs0_loss: 0.0121 - n_outputs1_loss: 0.0011 - val_loss: 0.0133 - val_n_outputs0_loss: 0.0126 - val_n_outputs1_loss: 6.8740e-04\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0127 - n_outputs0_loss: 0.0116 - n_outputs1_loss: 0.0011\n",
            "Epoch 00020: val_loss did not improve from 0.01193\n",
            "40/40 [==============================] - 6s 140ms/step - loss: 0.0127 - n_outputs0_loss: 0.0116 - n_outputs1_loss: 0.0011 - val_loss: 0.0123 - val_n_outputs0_loss: 0.0116 - val_n_outputs1_loss: 6.7888e-04\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0123 - n_outputs0_loss: 0.0112 - n_outputs1_loss: 0.0010\n",
            "Epoch 00021: val_loss improved from 0.01193 to 0.01121, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 144ms/step - loss: 0.0123 - n_outputs0_loss: 0.0112 - n_outputs1_loss: 0.0010 - val_loss: 0.0112 - val_n_outputs0_loss: 0.0105 - val_n_outputs1_loss: 6.6071e-04\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0119 - n_outputs0_loss: 0.0109 - n_outputs1_loss: 0.0010\n",
            "Epoch 00022: val_loss did not improve from 0.01121\n",
            "40/40 [==============================] - 6s 139ms/step - loss: 0.0119 - n_outputs0_loss: 0.0109 - n_outputs1_loss: 0.0010 - val_loss: 0.0113 - val_n_outputs0_loss: 0.0106 - val_n_outputs1_loss: 6.5990e-04\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0117 - n_outputs0_loss: 0.0107 - n_outputs1_loss: 0.0010\n",
            "Epoch 00023: val_loss did not improve from 0.01121\n",
            "40/40 [==============================] - 6s 141ms/step - loss: 0.0117 - n_outputs0_loss: 0.0107 - n_outputs1_loss: 0.0010 - val_loss: 0.0117 - val_n_outputs0_loss: 0.0111 - val_n_outputs1_loss: 6.5865e-04\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0116 - n_outputs0_loss: 0.0105 - n_outputs1_loss: 0.0010\n",
            "Epoch 00024: val_loss improved from 0.01121 to 0.01108, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 146ms/step - loss: 0.0116 - n_outputs0_loss: 0.0105 - n_outputs1_loss: 0.0010 - val_loss: 0.0111 - val_n_outputs0_loss: 0.0104 - val_n_outputs1_loss: 6.6900e-04\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0113 - n_outputs0_loss: 0.0103 - n_outputs1_loss: 9.9547e-04\n",
            "Epoch 00025: val_loss improved from 0.01108 to 0.01041, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 142ms/step - loss: 0.0113 - n_outputs0_loss: 0.0103 - n_outputs1_loss: 9.9547e-04 - val_loss: 0.0104 - val_n_outputs0_loss: 0.0098 - val_n_outputs1_loss: 6.3468e-04\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0110 - n_outputs0_loss: 0.0100 - n_outputs1_loss: 9.6275e-04\n",
            "Epoch 00026: val_loss improved from 0.01041 to 0.00997, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 142ms/step - loss: 0.0110 - n_outputs0_loss: 0.0100 - n_outputs1_loss: 9.6275e-04 - val_loss: 0.0100 - val_n_outputs0_loss: 0.0093 - val_n_outputs1_loss: 6.5036e-04\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0108 - n_outputs0_loss: 0.0099 - n_outputs1_loss: 9.0659e-04\n",
            "Epoch 00027: val_loss did not improve from 0.00997\n",
            "40/40 [==============================] - 6s 141ms/step - loss: 0.0108 - n_outputs0_loss: 0.0099 - n_outputs1_loss: 9.0659e-04 - val_loss: 0.0109 - val_n_outputs0_loss: 0.0103 - val_n_outputs1_loss: 6.5095e-04\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0101 - n_outputs0_loss: 0.0092 - n_outputs1_loss: 9.1602e-04\n",
            "Epoch 00028: val_loss did not improve from 0.00997\n",
            "40/40 [==============================] - 6s 140ms/step - loss: 0.0101 - n_outputs0_loss: 0.0092 - n_outputs1_loss: 9.1602e-04 - val_loss: 0.0103 - val_n_outputs0_loss: 0.0096 - val_n_outputs1_loss: 6.5986e-04\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0101 - n_outputs0_loss: 0.0092 - n_outputs1_loss: 9.1873e-04\n",
            "Epoch 00029: val_loss improved from 0.00997 to 0.00981, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 146ms/step - loss: 0.0101 - n_outputs0_loss: 0.0092 - n_outputs1_loss: 9.1873e-04 - val_loss: 0.0098 - val_n_outputs0_loss: 0.0092 - val_n_outputs1_loss: 6.3589e-04\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0097 - n_outputs0_loss: 0.0088 - n_outputs1_loss: 8.9057e-04\n",
            "Epoch 00030: val_loss improved from 0.00981 to 0.00969, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 143ms/step - loss: 0.0097 - n_outputs0_loss: 0.0088 - n_outputs1_loss: 8.9057e-04 - val_loss: 0.0097 - val_n_outputs0_loss: 0.0091 - val_n_outputs1_loss: 6.3527e-04\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0097 - n_outputs0_loss: 0.0088 - n_outputs1_loss: 8.9023e-04\n",
            "Epoch 00031: val_loss improved from 0.00969 to 0.00946, saving model to /content/mycar/models/mypilot.h5\n",
            "40/40 [==============================] - 6s 144ms/step - loss: 0.0097 - n_outputs0_loss: 0.0088 - n_outputs1_loss: 8.9023e-04 - val_loss: 0.0095 - val_n_outputs0_loss: 0.0088 - val_n_outputs1_loss: 6.3675e-04\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0095 - n_outputs0_loss: 0.0087 - n_outputs1_loss: 8.8515e-04\n",
            "Epoch 00032: val_loss did not improve from 0.00946\n",
            "40/40 [==============================] - 6s 140ms/step - loss: 0.0095 - n_outputs0_loss: 0.0087 - n_outputs1_loss: 8.8515e-04 - val_loss: 0.0100 - val_n_outputs0_loss: 0.0094 - val_n_outputs1_loss: 6.2596e-04\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0095 - n_outputs0_loss: 0.0087 - n_outputs1_loss: 8.7093e-04\n",
            "Epoch 00033: val_loss did not improve from 0.00946\n",
            "40/40 [==============================] - 6s 141ms/step - loss: 0.0095 - n_outputs0_loss: 0.0087 - n_outputs1_loss: 8.7093e-04 - val_loss: 0.0099 - val_n_outputs0_loss: 0.0093 - val_n_outputs1_loss: 6.2640e-04\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0093 - n_outputs0_loss: 0.0085 - n_outputs1_loss: 8.4575e-04\n",
            "Epoch 00034: val_loss did not improve from 0.00946\n",
            "40/40 [==============================] - 6s 139ms/step - loss: 0.0093 - n_outputs0_loss: 0.0085 - n_outputs1_loss: 8.4575e-04 - val_loss: 0.0095 - val_n_outputs0_loss: 0.0089 - val_n_outputs1_loss: 6.3749e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfERkGy821Xy"
      },
      "source": [
        "# 6> 자율주행모드로 동키카 운행하기\n",
        "\n",
        "* PC/노트북에 다운로드한 인공지능 모델(*.h5)를 폴더에 저장합니다.\n",
        "\n",
        "* 저장이 완료된 모델을 탑재한 라즈베리파이 SD카드를 동키카에 적재하고 동키카에 전원을 넣어 부팅합니다.\n",
        "\n",
        "* 노트북/PC에서 SSH로 동키카에 접속한 후, 아래의 명령을 입력하여 자율주행 모드로의 실행을 설정합니다.\n",
        "\n",
        "```\n",
        "# 동키카에 탑재된 라즈베리파이에서 수행할 코드\n",
        "\n",
        "$cd mycar [enter]\n",
        "$python manage.py drive --model /mycar/models/mypilot.h5 [enter]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxTAj6h2DTCe"
      },
      "source": [
        "## 7> PC에 설치된 Donkeycar 시뮬레이터에서 학습된 모델 작동시키기\n",
        "\n",
        "<참고>\n",
        "동키카 시뮬레이터 사용에 대해서는 아래의 링크를 참고하세요.\n",
        "* https://docs.donkeycar.com/guide/simulator/\n",
        "\n",
        "1. PC/Notebook에 설치된 simulator의 디렉토리로 이동합니다. 시뮬레이터 구동을 위한 동키카 프로젝트 폴더를 생성했다면, 해당디렉토리로 이동합니다(여기서는 ~/mysim으로 가정)\n",
        "2. 해당 디렉토리로 이동해서 simulator를 구동합니다.\n",
        "    * mysconfig.py파일에서 DONKEY_SIM_PATH가 시뮬레이터의 경로를 잘 설정하고 있는지 확인 부탁드립니다.\n",
        "3. 학습된 자율주행모델(*.h5)를 ~/mysim 디렉토리 아래의 models 디렉토리에 복사합니다.\n",
        "4. 아래의 명령어를 입력해서 자율주행을 실행합니다.\n",
        "    * ```$python manage.py drive --model models/mypilot.h5 ```    \n",
        "5. 유니티(Unity) 시뮬레이터창이 표시되고, 터미널에서 localhost:8887 접속에 대한 내용이 안내되면 웹브라우져를 실행하고 시뮬레이터에 접속합니다.\n",
        "6. 표시되는 웹 브라우져내의 drive창에서 아래의 Mode&Pilot의 Local Pilot으로 설정하면 자동주행을 합니다.\n",
        "\n",
        "![시뮬레이터 자율주행 설정](https://api.monosnap.com/file/download?id=PLU9FFdile460iwnUUCNvgdHKDLhHT)"
      ]
    }
  ]
}